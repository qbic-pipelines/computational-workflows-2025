{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 - Nextflow Basics: Introduction to channels and operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will begin exploring Nextflow, the programming language that powers the advanced nf-core pipelines you worked with last week. Your task is to dive into the core concepts and syntax of Nextflow, understanding how this language enables the development of scalable and reproducible workflows.\n",
    "\n",
    "Nextflow works quite differently from traditional programming languages like Python or Java that you may already be familiar with. To get started, it is essential to understand the foundational concepts that set Nextflow apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe the concept of Workflows, Processes and Channels we deal with in Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflows:\n",
    "The overall structure of a pipeline. They define the order of execution by connecting processes through channels. In DSL2 they are written inside a workflow { } block.\n",
    "\n",
    "Processes:\n",
    "The computational steps of a pipeline. Each process defines its inputs, outputs, and a script (bash, python, R, etc.). A process is executed automatically for each element received from a channel.\n",
    "\n",
    "Channels:\n",
    "The data streams between processes. They carry values or files. Each new element in a channel triggers a new execution of a process. Channels can be created and transformed with built-in operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to channels\n",
    "\n",
    "Please refer to the file  $\\texttt{channels\\_intro.nf}$ for the next exercises. Then run the code with the respective flag here below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Create a channel that enumerates the numbers from 1 to 10\n",
    "!nextflow run channels_intro.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Create a channel that gives out the entire alphabet\n",
    "!nextflow run channels_intro.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Create a channel that includes all files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - Create a channel that includes all TXT files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 - Create a channel that includes the files \"fastq_1.fq\" and \"fastq_2.fq\" in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 - go back to the time when you included all files. Are you sure that really ALL files are included? If not, how can you include them?\n",
    "!nextflow run channels_intro.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7 - get all filepairs in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you have a solid understanding of the basic concepts of channels in Nextflow, it’s time to experiment and see how they work in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, Nextflow has the concept of Operators to give and pass information inbetween channels.\n",
    "\n",
    "Please answer the questions in $\\texttt{basic\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mtiny_mercator\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36md107e83b31\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Extract the first item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Extract the last item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Use an operator to extract the first two items from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - Return the squared values of the channel\n",
    "!nextflow run basic_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 - Remember the previous task where you squared the values of the channel. Now, extract the first two items from the squared channel\n",
    "!nextflow run basic_channel_operations.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 - Remember when you used bash to reverse the output? Try to use map and Groovy to reverse the output\n",
    "!nextflow run basic_channel_operations.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7 - Use fromPath to include all fastq files in the \"files_dir\" directory, then use map to return a pair containing the file name and the file path (Hint: include groovy code)\n",
    "!nextflow run basic_channel_operations.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8 - Combine the items from the two channels into a single channel\n",
    "!nextflow run basic_channel_operations.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9 - Flatten the list in the channel\n",
    "!nextflow run basic_channel_operations.nf --step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10 - Collect the items of a channel into a list. What kind of channel is the output channel?\n",
    "!nextflow run basic_channel_operations.nf --step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of channel is the output channel?\n",
    "\n",
    "The output channel from is a **value channel** (singleton channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 11 -  From the input channel, create lists where each first item in the list of lists is the first item in the output channel, followed by a list of all the items its paired with\n",
    "!nextflow run basic_channel_operations.nf --step 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 12 - Create a channel that joins the input to the output channel. What do you notice?\n",
    "!nextflow run basic_channel_operations.nf --step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12 - What do you notice compared to Task 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupTuple() groups all items with the same key from one channel,\n",
    "join() combines matching items from two separate channels and only keeps items that exist in both channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 14 - Nextflow has the concept of maps. Write the names in the maps in this channel to a file called \"names.txt\". Each name should be on a new line. \n",
    "#           Store the file in the \"results\" directory under the name \"names.txt\"\n",
    "\n",
    "!nextflow run basic_channel_operations.nf --step 14\n",
    "\n",
    "!cat results/names.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we learned about Channels and Operators to deal with them, let's focus on Processes that make use of these channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{basics\\_processes.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mzen_brahmagupta\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m7d08a17680\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md3/8cf475\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello World!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - create a process that says Hello World! (add debug true to the process right after initializing to be sable to print the output to the console)\n",
    "!nextflow run basics_processes.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mvoluminous_poisson\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m7d08a17680\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m6b/c06088\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello World!\u001b[K\n",
      "\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m6b/c06088\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello World!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - create a process that says Hello World! using Python\n",
    "!nextflow run basics_processes.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36madoring_easley\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m7d08a17680\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mb2/74a219\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello world!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - create a process that reads in the string \"Hello world!\" from a channel and write it to command line\n",
    "!nextflow run basics_processes.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36madoring_goodall\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m1f/e58cc8\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - create a process that reads in the string \"Hello world!\" from a channel and write it to a file. \n",
    "!nextflow run basics_processes.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the file is created either in the results directory and qlso in the work directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mkickass_lumiere\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m17/4e4229\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "/Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/17/4e42295c6f657bac6322be8a03135a/uppercase.txt\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - create a process that reads in a string and converts it to uppercase and saves it to a file as output. View the path to the file in the console\n",
    "!nextflow run basics_processes.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mstupefied_stallman\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE  -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34me6/29cff3\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m0d/1b5216\u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34me6/29cff3\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m0d/1b5216\u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "HELLO WORLD!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - add another process that reads in the resulting file from UPPERCASE and print the content to the console (debug true).\n",
    "!nextflow run basics_processes.nf --step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to all the other runs. What changed in the output here and why?\n",
    "\n",
    "Task 5 uses `.view()` to show the file path, while Task 6 chains processes together - the UPPERCASE output file becomes input to PRINTUPPER, which displays the actual file contents (\"HELLO WORLD!\"). This demonstrates process chaining in Nextflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mevil_ptolemy\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS  -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf0/6fc237\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m67/9dfd8f\u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "/Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/67/9dfd8ffd246ba6ce727f1d495fb213/compressed.zip\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf0/6fc237\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m67/9dfd8f\u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "/Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/67/9dfd8ffd246ba6ce727f1d495fb213/compressed.zip\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - based on the paramater \"zip\" (see at the head of the file), create a process that zips the file created in the UPPERCASE process either in \"zip\", \"gzip\" OR \"bzip2\" format.\n",
    "#          Print out the path to the zipped file in the console\n",
    "!nextflow run basics_processes.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mwise_easley\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m46/504035\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS_ALL  -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m46/504035\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m23/eb6e1a\u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS_ALL\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m46/504035\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m23/eb6e1a\u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS_ALL\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "[/Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.bz2, /Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.gz, /Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.zip]\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m46/504035\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m23/eb6e1a\u001b[0;2m] \u001b[0;2m\u001b[mCOMPRESS_ALL\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "[/Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.bz2, /Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.gz, /Users/Nikita/Desktop/Studium/Master/Comp Workflows/computational-workflows-2025/notebooks/day_04/work/23/eb6e1ac36222aa354d13ce1f0c7490/compressed.zip]\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 8 - Create a process that zips the file created in the UPPERCASE process in \"zip\", \"gzip\" AND \"bzip2\" format. Print out the paths to the zipped files in the console\n",
    "!nextflow run basics_processes.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mamazing_brazil\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc4be722323\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mc9/629690\u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mc9/629690\u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Task 9 - Create a process that reads in a list of names and titles from a channel and writes them to a file.\n",
    "#           Store the file in the \"results\" directory under the name \"names.tsv\"\n",
    "!nextflow run basics_processes.nf --step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results/names.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's try some more advanced Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{advanced\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To come closer to actual pipelines, we introduce the concept of \"meta-maps\" which you can imagine as dictionaries that are passed with data via channels containing crucial metadata on the sample. \n",
    "\n",
    "Also, we will come back to samplesheets which you should remember from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mconfident_faraday\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mconfident_faraday\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "[sample:CONTROL_REP1, fastq_1:fq_1_R1.fastq.gz, fastq_2:fq_1_R2.fastq.gz, strandedness:auto]\n",
      "[sample:CONTROL_REP2, fastq_1:fq_2_R1.fastq.gz, fastq_2:fq_2_R2.fastq.gz, strandedness:forward]\n",
      "[sample:CONTROL_REP3, fastq_1:fq_3_R1.fastq.gz, fastq_2:fq_3_R2.fastq.gz, strandedness:reverse]\n",
      "[sample:CONTROL_REP1, fastq_1:fq_4_R1.fastq.gz, fastq_2:fq_4_R2.fastq.gz, strandedness:auto]\n",
      "[sample:CONTROL_REP1, fastq_1:fq_1_R1.fastq.gz, fastq_2:fq_1_R2.fastq.gz, strandedness:auto]\n",
      "[sample:CONTROL_REP2, fastq_1:fq_2_R1.fastq.gz, fastq_2:fq_2_R2.fastq.gz, strandedness:forward]\n",
      "[sample:CONTROL_REP3, fastq_1:fq_3_R1.fastq.gz, fastq_2:fq_3_R2.fastq.gz, strandedness:reverse]\n",
      "[sample:CONTROL_REP1, fastq_1:fq_4_R1.fastq.gz, fastq_2:fq_4_R2.fastq.gz, strandedness:auto]\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Read in the samplesheet.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mzen_panini\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mzen_panini\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "[[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]\n",
      "[[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Read in the samplesheet and create a meta-map with all metadata and another list with the filenames ([[metadata_1 : metadata_1, ...], [fastq_1, fastq_2]]).\n",
    "#          Set the output to a new channel \"in_ch\" and view the channel. YOU WILL NEED TO COPY AND PASTE THIS CODE INTO SOME OF THE FOLLOWING TASKS (sorry for that).\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mcheeky_edison\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mcheeky_edison\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "FORWARD: [[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]\n",
      "REVERSE: [[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]\n",
      "AUTO: [[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]]\n",
      "AUTO: [[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]\n",
      "FORWARD: [[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]\n",
      "REVERSE: [[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]\n",
      "AUTO: [[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]]\n",
      "AUTO: [[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Now we assume that we want to handle different \"strandedness\" values differently. \n",
    "#          Split the channel into the right amount of channels and write them all to stdout so that we can understand which is which.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 3 -dump-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgloomy_albattani\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgloomy_albattani\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m92d27bba08\u001b[m\n",
      "\u001b[K\n",
      "[[CONTROL_REP1, auto], [[[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]], [[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]]]\n",
      "[[CONTROL_REP2, forward], [[[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]]]\n",
      "[[CONTROL_REP3, reverse], [[[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]]]\n",
      "[[CONTROL_REP1, auto], [[[sample:CONTROL_REP1, strandedness:auto], [fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]], [[sample:CONTROL_REP1, strandedness:auto], [fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]]]\n",
      "[[CONTROL_REP2, forward], [[[sample:CONTROL_REP2, strandedness:forward], [fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]]]\n",
      "[[CONTROL_REP3, reverse], [[[sample:CONTROL_REP3, strandedness:reverse], [fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]]]\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Group together all files with the same sample-id and strandedness value.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's finally time to link processes and channels with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the file $\\texttt{link\\_p\\_c.nf}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `link_p_c.nf` \u001b[0;2m[\u001b[0;1;36mdisturbed_kalman\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m3834507de4\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `link_p_c.nf` \u001b[0;2m[\u001b[0;1;36mdisturbed_kalman\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m3834507de4\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS   -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS   -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (5)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m  \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m67/b8f466\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m3\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 11\u001b[K\n",
      "\u001b[2mexecutor >  local (5)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m  \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m67/b8f466\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m3\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 11\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m91/330dd4\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m10\u001b[2m)\u001b[m\u001b[2m |\u001b[m 10 of 11\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m91/330dd4\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m10\u001b[2m)\u001b[m\u001b[2m |\u001b[m 10 of 11\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mbe/3e9b3e\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m11\u001b[2m)\u001b[m\u001b[2m |\u001b[m 11 of 11\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m84/d9b59a\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mbe/3e9b3e\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m11\u001b[2m)\u001b[m\u001b[2m |\u001b[m 11 of 11\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nextflow run link_p_c.nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give a list with the paths to the chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk files created:\n",
      "- results/chunk_h_w_1.txt\n",
      "- results/chunk_h_w_2.txt\n",
      "- results/chunk_h_w_3.txt\n",
      "- results/chunk_c_w_1.txt\n",
      "- results/chunk_c_w_2.txt\n",
      "- results/chunk_c_w_3.txt\n",
      "- results/chunk_c_w_4.txt\n",
      "- results/chunk_c_w_5.txt\n",
      "- results/chunk_c_w_6.txt\n",
      "- results/chunk_c_w_7.txt\n",
      "- results/chunk_c_w_8.txt\n",
      "\n",
      "Total number of chunk files: 11\n"
     ]
    }
   ],
   "source": [
    "# Based on samplesheet_2.csv, the chunk files created are:\n",
    "# From \"Hello World\" (block_size=4): \"Hell\", \"o Wo\", \"rld\"\n",
    "# From \"Computational Workflows\" (block_size=3): \"Com\", \"put\", \"ati\", \"ona\", \"l W\", \"ork\", \"flo\", \"ws\"\n",
    "\n",
    "chunk_files = [\n",
    "    \"results/chunk_h_w_1.txt\",  # \"Hell\"\n",
    "    \"results/chunk_h_w_2.txt\",  # \"o Wo\" \n",
    "    \"results/chunk_h_w_3.txt\",  # \"rld\"\n",
    "    \"results/chunk_c_w_1.txt\",  # \"Com\"\n",
    "    \"results/chunk_c_w_2.txt\",  # \"put\"\n",
    "    \"results/chunk_c_w_3.txt\",  # \"ati\"\n",
    "    \"results/chunk_c_w_4.txt\",  # \"ona\"\n",
    "    \"results/chunk_c_w_5.txt\",  # \"l W\"\n",
    "    \"results/chunk_c_w_6.txt\",  # \"ork\"\n",
    "    \"results/chunk_c_w_7.txt\",  # \"flo\"\n",
    "    \"results/chunk_c_w_8.txt\"   # \"ws\"\n",
    "]\n",
    "\n",
    "print(\"Chunk files created:\")\n",
    "for file in chunk_files:\n",
    "    print(f\"- {file}\")\n",
    "    \n",
    "print(f\"\\nTotal number of chunk files: {len(chunk_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why was CONVERTTOUPPER run so often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERTTOUPPER runs 11 times because:\n",
      "1. SPLITLETTERS creates 11 chunk files total\n",
      "2. The flatten operator separates each file into individual channel elements\n",
      "3. CONVERTTOUPPER processes each file independently\n",
      "4. Nextflow automatically parallelizes process execution over channel items\n"
     ]
    }
   ],
   "source": [
    "# CONVERTTOUPPER runs 11 times because the flatten operator creates 11 separate files\n",
    "# from the SPLITLETTERS process:\n",
    "\n",
    "# From \"Hello World\" (block_size=4): 3 chunks\n",
    "# From \"Computational Workflows\" (block_size=3): 8 chunks\n",
    "# Total: 11 chunks\n",
    "\n",
    "# Each chunk file becomes a separate input to the CONVERTTOUPPER process.\n",
    "# In Nextflow, when a channel contains multiple items (11 chunk files),\n",
    "# the process runs once for each item in the channel.\n",
    "\n",
    "# This demonstrates the core principle of Nextflow: \n",
    "# processes automatically parallelize over channel elements.\n",
    "\n",
    "print(\"CONVERTTOUPPER runs 11 times because:\")\n",
    "print(\"1. SPLITLETTERS creates 11 chunk files total\")\n",
    "print(\"2. The flatten operator separates each file into individual channel elements\")\n",
    "print(\"3. CONVERTTOUPPER processes each file independently\")\n",
    "print(\"4. Nextflow automatically parallelizes process execution over channel items\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
