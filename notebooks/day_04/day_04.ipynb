{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 - Nextflow Basics: Introduction to channels and operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will begin exploring Nextflow, the programming language that powers the advanced nf-core pipelines you worked with last week. Your task is to dive into the core concepts and syntax of Nextflow, understanding how this language enables the development of scalable and reproducible workflows.\n",
    "\n",
    "Nextflow works quite differently from traditional programming languages like Python or Java that you may already be familiar with. To get started, it is essential to understand the foundational concepts that set Nextflow apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe the concept of Workflows, Processes and Channels we deal with in Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nextflow is built on a dataflow programming paradigm.  \n",
    "\n",
    "- Workflows: A workflow is a higher-level composition that connects processes via channels and defines the pipeline logic.  \n",
    "\n",
    "- Processes: A process in Nextflow encapsulates a computational step (script, command, tool) you want to run. It has declared inputs and outputs. Independent processes execute tasks when their inputs are ready. Processes don’t share mutable state; they communicate only via channels. \n",
    "\n",
    "Channels: They are the “wires” through which data flows from producers (process outputs) to consumers (process inputs).\n",
    "\n",
    "Thus, a pipeline is essentially a graph: processes are nodes, channels are edges defining how data flows.  \n",
    "\n",
    "Quellen: https://www.nextflow.io/docs/latest/workflow.html, https://medium.com/23andme-engineering/introduction-to-nextflow-4d0e3b6768d1, https://www.nextflow.io/docs/latest/process.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to channels\n",
    "\n",
    "Please refer to the file  $\\texttt{channels\\_intro.nf}$ for the next exercises. Then run the code with the respective flag here below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mberserk_sammet\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m937e040295\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check example\n",
    "!nextflow run channels_intro.nf --step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mfocused_brattain\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m937e040295\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check example\n",
    "!nextflow run channels_intro.nf --step 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mexotic_planck\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m937e040295\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check example\n",
    "!nextflow run channels_intro.nf --step 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36msoggy_rutherford\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mee2744220b\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Create a channel that enumerates the numbers from 1 to 10\n",
    "!nextflow run channels_intro.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mfestering_stonebraker\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m327ad19a85\u001b[m\n",
      "\u001b[K\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Create a channel that gives out the entire alphabet\n",
    "!nextflow run channels_intro.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mgolden_moriondo\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m327ad19a85\u001b[m\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Create a channel that includes all files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mhungry_heisenberg\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m327ad19a85\u001b[m\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Create a channel that includes all TXT files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mmighty_gilbert\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m327ad19a85\u001b[m\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - Create a channel that includes the files \"fastq_1.fq\" and \"fastq_2.fq\" in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mfestering_mestorf\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m96f2b422d2\u001b[m\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_2.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_1.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - go back to the time when you included all files. \n",
    "# Are you sure that really ALL files are included? If not, how can you include them?\n",
    "!nextflow run channels_intro.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mjolly_cray\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m0814395a3e\u001b[m\n",
      "\u001b[K\n",
      "[fastq3, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq]]\n",
      "[SRR4, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq]]\n",
      "[SRR2, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq]]\n",
      "[fastq, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq]]\n",
      "[fastq5, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq]]\n",
      "[SRR1, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq]]\n",
      "[fastq1, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq]]\n",
      "[fastq4, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq]]\n",
      "[fastq2, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq]]\n",
      "[file, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt]]\n",
      "[SRR3, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq]]\n",
      "[SRR5, [/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq]]\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - get all filepairs in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you have a solid understanding of the basic concepts of channels in Nextflow, it’s time to experiment and see how they work in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, Nextflow has the concept of Operators to give and pass information inbetween channels.\n",
    "\n",
    "Please answer the questions in $\\texttt{basic\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36madoring_mclean\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc8a597c056\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Extract the first item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgolden_linnaeus\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m642c12c221\u001b[m\n",
      "\u001b[K\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Extract the last item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mprickly_neumann\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m642c12c221\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Use an operator to extract the first two items from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgolden_wegener\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mad0f1ab6d6\u001b[m\n",
      "\u001b[K\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Return the squared values of the channel\n",
    "!nextflow run basic_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36msilly_payne\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mad0f1ab6d6\u001b[m\n",
      "\u001b[K\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - Remember the previous task where you squared the values of the channel. \n",
    "# Now, extract the first two items from the squared channel\n",
    "!nextflow run basic_channel_operations.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mamazing_sax\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m4927197e8a\u001b[m\n",
      "\u001b[K\n",
      "[Swift, Taylor]\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - Remember when you used bash to reverse the output? \n",
    "# Try to use map and Groovy to reverse the output\n",
    "!nextflow run basic_channel_operations.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mdreamy_plateau\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mec611231c6\u001b[m\n",
      "\u001b[K\n",
      "[fastq_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq]\n",
      "[SRR4_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq]\n",
      "[SRR1_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq]\n",
      "[fastq3_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq]\n",
      "[fastq1_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq]\n",
      "[fastq.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq]\n",
      "[fastq2_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq]\n",
      "[fastq3_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq]\n",
      "[SRR4_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq]\n",
      "[SRR2_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq]\n",
      "[SRR5_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq]\n",
      "[SRR2_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq]\n",
      "[fastq_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq]\n",
      "[fastq5_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq]\n",
      "[fastq5_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq]\n",
      "[SRR.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq]\n",
      "[SRR1_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq]\n",
      "[fastq4_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq]\n",
      "[fastq1_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq]\n",
      "[SRR3_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq]\n",
      "[fastq4_2.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq]\n",
      "[fastq2_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq]\n",
      "[SRR3_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq]\n",
      "[SRR5_1.fq, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq]\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - Use fromPath to include all fastq files in the \"files_dir\" directory, then use map to return a pair containing the file name and the file path (Hint: include groovy code)\n",
    "!nextflow run basic_channel_operations.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mwise_sinoussi\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mf75a2f797e\u001b[m\n",
      "\u001b[K\n",
      "a\n",
      "b\n",
      "c\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Task 8 - Combine the items from the two channels into a single channel\n",
    "!nextflow run basic_channel_operations.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mchaotic_woese\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m4b844ea913\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Task 9 - Flatten the list in the channel\n",
    "!nextflow run basic_channel_operations.nf --step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mridiculous_knuth\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m076998424b\u001b[m\n",
      "\u001b[K\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Task 10 - Collect the items of a channel into a list. What kind of channel is the output channel?\n",
    "!nextflow run basic_channel_operations.nf --step 10\n",
    "\n",
    "# The collect operator returns a value channel containing a single item, \n",
    "# which is a list of all items emitted by the input channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of channel is the output channel?  \n",
    "The collect operator returns a value channel containing a single item, which is a list of all items emitted by the input channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mbackstabbing_lichterman\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mba16f89ca5\u001b[m\n",
      "\u001b[K\n",
      "[1, [V, f, B]]\n",
      "[3, [M, G, 33]]\n",
      "[2, [O, L, E]]\n"
     ]
    }
   ],
   "source": [
    "# Task 11 -  From the input channel, create lists where each first item in the list of lists is the first item in the output channel, followed by a list of all the items its paired with\n",
    "!nextflow run basic_channel_operations.nf --step 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgloomy_colden\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mf4a810abb3\u001b[m\n",
      "\u001b[K\n",
      "[1, V, f]\n",
      "[3, M, G]\n",
      "[2, O, L]\n",
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mintergalactic_lumiere\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mf4a810abb3\u001b[m\n",
      "\u001b[K\n",
      "[1, V, f]\n",
      "[3, M, G]\n",
      "[2, O, L]\n",
      "[1, B, null]\n",
      "[3, 33, null]\n",
      "[2, null, E]\n"
     ]
    }
   ],
   "source": [
    "# Task 12 - Create a channel that joins the input to the output channel. What do you notice?\n",
    "!nextflow run basic_channel_operations.nf --step 12\n",
    "!nextflow run basic_channel_operations.nf --step 122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12 - What do you notice compared to Task 11?  \n",
    "The join operator transforms a sequence of tuples like (K, V1, V2, ..) and (K, W1, W1, ..) into a sequence of tuples like (K, V1, V2, .., W1, W2, ..). By default, the first element of each item is used as the key. By default, unmatched items are discarded. The remainder option can be used to emit them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mastonishing_jepsen\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m0e42119425\u001b[m\n",
      "\u001b[K\n",
      "Odd numbers: [1, 3, 5, 7, 9]\n",
      "Even numbers: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Task 13 - Split the input channel into two channels, one of all the even numbers and the other of all the odd numbers.\n",
    "#           Write them to stdout including information about which is which\n",
    "!nextflow run basic_channel_operations.nf --step 13 -dump-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mvoluminous_lichterman\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36md188aafa6d\u001b[m\n",
      "\u001b[K\n",
      "Snape\n",
      "Albus\n",
      "Ron\n",
      "Hagrid\n",
      "Dobby\n",
      "Hermione\n",
      "Harry\n"
     ]
    }
   ],
   "source": [
    "# Task 14 - Nextflow has the concept of maps. \n",
    "# Write the names in the maps in this channel to a file called \"names.txt\". \n",
    "# Each name should be on a new line. \n",
    "# Store the file in the \"results\" directory under the name \"names.txt\"\n",
    "\n",
    "!nextflow run basic_channel_operations.nf --step 14\n",
    "\n",
    "!cat results/names.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we learned about Channels and Operators to deal with them, let's focus on Processes that make use of these channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{basics\\_processes.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mcurious_cori\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mdf317feb24\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m73/b31345\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello world!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - create a process that says Hello World! (add debug true to the process right after initializing to be sable to print the output to the console)\n",
    "!nextflow run basics_processes.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36msleepy_pauling\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mdc64163480\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m20/95f639\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m20/95f639\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello world!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - create a process that says Hello World! using Python\n",
    "!nextflow run basics_processes.nf --step 2\n",
    "\n",
    "# Also possible with shebang in script\n",
    "# #!/usr/bin/env python as first line in script section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36madmiring_jepsen\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc3011366e2\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mc8/6ace09\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello world!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - create a process that reads in the string \"Hello world!\" from a channel and write it to command line\n",
    "!nextflow run basics_processes.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About bin dirctory:\n",
    "# Nextflow automatically adds a directory named 'bin' located in the same directory as the \n",
    "# main script to the PATH environment variable of all processes.\n",
    "# This allows you to place executable scripts in that directory and invoke them directly from your process scripts.\n",
    "# This is particularly useful for organizing and reusing scripts across multiple processes within the same workflow.\n",
    "# You need to make the script executable with: chmod +x scriptname, or chmod a+x scriptname (all users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36magitated_ritchie\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m0bfb5aa036\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m9c/59848a\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - create a process that reads in the string \"Hello world!\" from a channel and write it to a file. \n",
    "!nextflow run basics_processes.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add debug true, Nextflow prints the path of the work directory for that process: [9c/59848a]  \n",
    "Inside that work directory, the greeting.txt can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mprickly_gilbert\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m687f23068f\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34ma3/5b7b15\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34ma3/5b7b15\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/a3/5b7b154ba0b346969df355cdcb76eb/uppercase.txt\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - create a process that reads in a string and converts it to uppercase and saves it to a file as output. View the path to the file in the console\n",
    "!nextflow run basics_processes.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mcompassionate_banach\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m9e06b5a980\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE  -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf4/de3d93\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER    -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf4/de3d93\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m85/fb3883\u001b[0;2m] \u001b[0;2m\u001b[mPRINTUPPER\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "HELLO WORLD!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - add another process that reads in the resulting file from UPPERCASE and print the content to the console (debug true).\n",
    "!nextflow run basics_processes.nf --step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comared to all the other runs. What changed in the output here and why?  \n",
    "So far we had only one process called in our workflow. in this task we first call the UPPERCASE process to write the file, before we can read the file to run the process PRINTUPPER. This is why now 2 [] occure and are executed after each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mprickly_pike\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36ma850a52625\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mZIPFILE       -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md7/9198db\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mZIPFILE           -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md7/9198db\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mce/0e464e\u001b[0;2m] \u001b[0;2m\u001b[mZIPFILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m      \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "  adding: greeting.txt (stored 0%)\u001b[K\n",
      "Created file: uppercase.zip\u001b[K\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/ce/0e464e268bbbe48dfa0bd67569154e/uppercase.zip\u001b[K\n",
      "\u001b[8A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md7/9198db\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mce/0e464e\u001b[0;2m] \u001b[0;2m\u001b[mZIPFILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m      \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "  adding: greeting.txt (stored 0%)\u001b[K\n",
      "Created file: uppercase.zip\u001b[K\n",
      "\u001b[K\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/ce/0e464e268bbbe48dfa0bd67569154e/uppercase.zip\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - based on the paramater \"zip\" (see at the head of the file), create a process that zips the file created in the UPPERCASE process either in \"zip\", \"gzip\" OR \"bzip2\" format.\n",
    "#          Print out the path to the zipped file in the console\n",
    "!nextflow run basics_processes.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mevil_nobel\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m29610a1ec7\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mZIP_VARIANTS  -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m78/efb249\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mZIP_VARIANTS      -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m78/efb249\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m3b/538dde\u001b[0;2m] \u001b[0;2m\u001b[mZIP_VARIANTS\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "  adding: greeting.txt (stored 0%)\u001b[K\n",
      "Created file: uppercase.zip\u001b[K\n",
      "Created file: uppercase.gz\u001b[K\n",
      "Created file: uppercase.bz2\u001b[K\n",
      "\u001b[K\n",
      "[/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.bz2, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.gz, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.zip]\u001b[K\n",
      "\u001b[10A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m78/efb249\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m3b/538dde\u001b[0;2m] \u001b[0;2m\u001b[mZIP_VARIANTS\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "  adding: greeting.txt (stored 0%)\u001b[K\n",
      "Created file: uppercase.zip\u001b[K\n",
      "Created file: uppercase.gz\u001b[K\n",
      "Created file: uppercase.bz2\u001b[K\n",
      "\u001b[K\n",
      "[/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.bz2, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.gz, /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/3b/538dded14aa3299624dc5a8424bfcf/uppercase.zip]\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 8 - Create a process that zips the file created in the UPPERCASE process in \"zip\", \"gzip\" AND \"bzip2\" format. Print out the paths to the zipped files in the console\n",
    "!nextflow run basics_processes.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mangry_torricelli\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m94a25a768f\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (3)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m3f/cfcc47\u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 7\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (7)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m02/27a2b3\u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE\u001b[33;2m (\u001b[0;33m4\u001b[2m)\u001b[m\u001b[2m |\u001b[m 7 of 7\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (7)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m02/27a2b3\u001b[0;2m] \u001b[0;2m\u001b[mWRITETOFILE\u001b[33;2m (\u001b[0;33m4\u001b[2m)\u001b[m\u001b[2m |\u001b[m 7 of 7\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Task 9 - Create a process that reads in a list of names and titles from a channel and writes them to a file.\n",
    "#           Store the file in the \"results\" directory under the name \"names.tsv\"\n",
    "!nextflow run basics_processes.nf --step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's try some more advanced Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{advanced\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To come closer to actual pipelines, we introduce the concept of \"meta-maps\" which you can imagine as dictionaries that are passed with data via channels containing crucial metadata on the sample. \n",
    "\n",
    "Also, we will come back to samplesheets which you should remember from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mberserk_escher\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mb4e40b479d\u001b[m\n",
      "\u001b[K\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Read in the samplesheet.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36msharp_panini\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mcdb95245c4\u001b[m\n",
      "\u001b[K\n",
      "[[CONTROL_REP1, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz, auto], [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]]\n",
      "[[CONTROL_REP2, fq_2_R1.fastq.gz, fq_2_R2.fastq.gz, forward], [null, fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]]\n",
      "[[CONTROL_REP3, fq_3_R1.fastq.gz, fq_3_R2.fastq.gz, reverse], [null, fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]]\n",
      "[[CONTROL_REP1, fq_4_R1.fastq.gz, fq_4_R2.fastq.gz, auto], [null, fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]]\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Read in the samplesheet and create a meta-map with all metadata and another list with the filenames ([[metadata_1 : metadata_1, ...], [fastq_1, fastq_2]]).\n",
    "#          Set the output to a new channel \"in_ch\" and view the channel. YOU WILL NEED TO COPY AND PASTE THIS CODE INTO SOME OF THE FOLLOWING TASKS (sorry for that).\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mromantic_rutherford\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m48f5a33fb2\u001b[m\n",
      "\u001b[K\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP1\n",
      "\tfastq_1=fq_1_R1.fastq.gz\n",
      "\tfastq_2=fq_1_R2.fastq.gz\n",
      "\tstrandedness=auto\n",
      "File-Listen:\n",
      "\t[null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP2\n",
      "\tfastq_1=fq_2_R1.fastq.gz\n",
      "\tfastq_2=fq_2_R2.fastq.gz\n",
      "\tstrandedness=forward\n",
      "File-Listen:\n",
      "\t[null, fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP3\n",
      "\tfastq_1=fq_3_R1.fastq.gz\n",
      "\tfastq_2=fq_3_R2.fastq.gz\n",
      "\tstrandedness=reverse\n",
      "File-Listen:\n",
      "\t[null, fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP1\n",
      "\tfastq_1=fq_4_R1.fastq.gz\n",
      "\tfastq_2=fq_4_R2.fastq.gz\n",
      "\tstrandedness=auto\n",
      "File-Listen:\n",
      "\t[null, fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Now we assume that we want to handle different \"strandedness\" values differently. \n",
    "#          Split the channel into the right amount of channels and write them all to stdout so that we can understand which is which.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 3 -dump-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `advanced_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36melated_ride\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m2e913d0d37\u001b[m\n",
      "\u001b[K\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP1\n",
      "\tfastq_1=fq_1_R1.fastq.gz\n",
      "\tfastq_2=fq_1_R2.fastq.gz\n",
      "\tstrandedness=auto\n",
      "File-Listen:\n",
      "\t[null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP2\n",
      "\tfastq_1=fq_2_R1.fastq.gz\n",
      "\tfastq_2=fq_2_R2.fastq.gz\n",
      "\tstrandedness=forward\n",
      "File-Listen:\n",
      "\t[null, fq_2_R1.fastq.gz, fq_2_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP3\n",
      "\tfastq_1=fq_3_R1.fastq.gz\n",
      "\tfastq_2=fq_3_R2.fastq.gz\n",
      "\tstrandedness=reverse\n",
      "File-Listen:\n",
      "\t[null, fq_3_R1.fastq.gz, fq_3_R2.fastq.gz]\n",
      "Metadaten:\n",
      "\tsample=CONTROL_REP1\n",
      "\tfastq_1=fq_4_R1.fastq.gz\n",
      "\tfastq_2=fq_4_R2.fastq.gz\n",
      "\tstrandedness=auto\n",
      "File-Listen:\n",
      "\t[null, fq_4_R1.fastq.gz, fq_4_R2.fastq.gz]\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Group together all files with the same sample-id and strandedness value.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's finally time to link processes and channels with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the file $\\texttt{link\\_p\\_c.nf}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `link_p_c.nf` \u001b[0;2m[\u001b[0;1;36msmall_solvay\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m73b3894485\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS   -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS   -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS  \u001b[2m |\u001b[m 0 of 2\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2mexecutor >  local (2)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mfd/46f959\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 2\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER   -\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "Processing: Hello World with block_size: 4\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   H   e   l   l  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   o       W   o  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   r   l   d  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "\u001b[K\n",
      "\u001b[17A\n",
      "\u001b[2mexecutor >  local (8)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m79/4f4d20\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m  \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf0/594f48\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m6\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 11\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "Processing: Hello World with block_size: 4\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   H   e   l   l  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   o       W   o  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   r   l   d  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "\u001b[K\n",
      "Processing: Computational Workflows with block_size: 3\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   C   o   m  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   p   u   t  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   a   t   i  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_003 with content:\u001b[K\n",
      "0000000   o   n   a  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_004 with content:\u001b[K\n",
      "0000000   l       W  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_005 with content:\u001b[K\n",
      "0000000   o   r   k  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_006 with content:\u001b[K\n",
      "0000000   f   l   o  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_007 with content:\u001b[K\n",
      "0000000   w   s  \\n\u001b[K\n",
      "0000003\u001b[K\n",
      "\u001b[K\n",
      "COM\u001b[K\n",
      "\u001b[K\n",
      "ONA\u001b[K\n",
      "\u001b[K\n",
      "\u001b[47A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m79/4f4d20\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf6/d3a2e2\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m11\u001b[2m)\u001b[m\u001b[2m |\u001b[m 11 of 11\u001b[32m ✔\u001b[m\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "Processing: Hello World with block_size: 4\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   H   e   l   l  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   o       W   o  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   r   l   d  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "\u001b[K\n",
      "Processing: Computational Workflows with block_size: 3\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   C   o   m  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   p   u   t  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   a   t   i  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_003 with content:\u001b[K\n",
      "0000000   o   n   a  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_004 with content:\u001b[K\n",
      "0000000   l       W  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_005 with content:\u001b[K\n",
      "0000000   o   r   k  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_006 with content:\u001b[K\n",
      "0000000   f   l   o  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_007 with content:\u001b[K\n",
      "0000000   w   s  \\n\u001b[K\n",
      "0000003\u001b[K\n",
      "\u001b[K\n",
      "COM\u001b[K\n",
      "\u001b[K\n",
      "ONA\u001b[K\n",
      "\u001b[K\n",
      "HELL\u001b[K\n",
      "\u001b[K\n",
      "PUT\u001b[K\n",
      "\u001b[K\n",
      "FLO\u001b[K\n",
      "\u001b[K\n",
      "ATI\u001b[K\n",
      "\u001b[K\n",
      "O WO\u001b[K\n",
      "\u001b[K\n",
      "RLD\u001b[K\n",
      "\u001b[K\n",
      "L W\u001b[K\n",
      "\u001b[K\n",
      "WS\u001b[K\n",
      "\u001b[K\n",
      "ORK\u001b[K\n",
      "\u001b[K\n",
      "\u001b[65A\n",
      "\u001b[2mexecutor >  local (13)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m79/4f4d20\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m   \u001b[2m |\u001b[m 2 of 2\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mf6/d3a2e2\u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER\u001b[33;2m (\u001b[0;33m11\u001b[2m)\u001b[m\u001b[2m |\u001b[m 11 of 11\u001b[32m ✔\u001b[m\u001b[K\n",
      "Input channel: [[block_size:4], Hello World]\u001b[K\n",
      "Input channel: [[block_size:3], Computational Workflows]\u001b[K\n",
      "Processing: Hello World with block_size: 4\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   H   e   l   l  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   o       W   o  \\n\u001b[K\n",
      "0000005\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   r   l   d  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "\u001b[K\n",
      "Processing: Computational Workflows with block_size: 3\u001b[K\n",
      "Created file: chunk_000 with content:\u001b[K\n",
      "0000000   C   o   m  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_001 with content:\u001b[K\n",
      "0000000   p   u   t  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_002 with content:\u001b[K\n",
      "0000000   a   t   i  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_003 with content:\u001b[K\n",
      "0000000   o   n   a  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_004 with content:\u001b[K\n",
      "0000000   l       W  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_005 with content:\u001b[K\n",
      "0000000   o   r   k  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_006 with content:\u001b[K\n",
      "0000000   f   l   o  \\n\u001b[K\n",
      "0000004\u001b[K\n",
      "Created file: chunk_007 with content:\u001b[K\n",
      "0000000   w   s  \\n\u001b[K\n",
      "0000003\u001b[K\n",
      "\u001b[K\n",
      "COM\u001b[K\n",
      "\u001b[K\n",
      "ONA\u001b[K\n",
      "\u001b[K\n",
      "HELL\u001b[K\n",
      "\u001b[K\n",
      "PUT\u001b[K\n",
      "\u001b[K\n",
      "FLO\u001b[K\n",
      "\u001b[K\n",
      "ATI\u001b[K\n",
      "\u001b[K\n",
      "O WO\u001b[K\n",
      "\u001b[K\n",
      "RLD\u001b[K\n",
      "\u001b[K\n",
      "L W\u001b[K\n",
      "\u001b[K\n",
      "WS\u001b[K\n",
      "\u001b[K\n",
      "ORK\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nextflow run link_p_c.nf\n",
    "\n",
    "# Lateron if-clause with params.step == 1 was added, so for rerunning use:\n",
    "# !nextflow run link_p_c.nf --step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give a list with the paths to the chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Chunk-Dateien:\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_007.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_000.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_004.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_006.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_005.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_001.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_003.txt\n",
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results/upper_chunk_002.txt\n"
     ]
    }
   ],
   "source": [
    "# give alist fo chunk files by listing all files in results directory that start with \"upper_chunk_\" with python and without nextflow\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Verzeichnis, in dem die resultierenden Dateien liegen\n",
    "results_dir = \"/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/results\"\n",
    "\n",
    "# Alle Dateien auflisten, die mit \"upper_chunk_\" beginnen\n",
    "chunk_files = glob.glob(os.path.join(results_dir, \"upper_chunk_*\"))\n",
    "\n",
    "# Optional: absolute Pfade\n",
    "chunk_files_abs = [os.path.abspath(f) for f in chunk_files]\n",
    "\n",
    "# Ausgabe\n",
    "print(\"Gefundene Chunk-Dateien:\")\n",
    "for f in chunk_files_abs:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why was CONVERTTOUPPER run so often?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Verhalten ist erwartet, weil Nextflow pro Input-Tuple ein Task ausführt.  \n",
    "\n",
    "split_ch.flatMap { meta, files -> \n",
    "    files.collect { file -> tuple(meta, file) } \n",
    "}  \n",
    "- split_ch ist der Output von SPLITLETTERS, der pro Sample mehrere Chunk-Dateien enthält (je nach block_size und Dateigröße).\n",
    "- flatMap erzeugt für jede Chunk-Datei einen Input-Tuple für CONVERTTOUPPER.\n",
    "- CONVERTTOUPPER schreibt für jede dieser Dateien eine neue Output-Datei in results/.  \n",
    "Ergebnis: so viele Output-Dateien wie Chunks insgesamt.  \n",
    "\n",
    "Angenommen, man hat 2 Samples, die jeweils in 4 Chunks gesplittet werden:  \n",
    "split_ch enthält 2 × 4 = 8 Chunk-Dateien.  \n",
    "flatMap wandelt jede Datei in einen eigenen Input für CONVERTTOUPPER.  \n",
    "Daher erzeugt CONVERTTOUPPER 8 Dateien in results/.  \n",
    "\n",
    "Wenn man weniger Output-Dateien möchte, müsste man entweder:\n",
    "- Größere block_size wählen, sodass weniger Chunks entstehen.\n",
    "- Nach SPLITLETTERS die Chunks wieder zusammenfassen (z. B. collect()), bevor man sie in CONVERTTOUPPER einspeist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `link_p_c.nf` \u001b[0;2m[\u001b[0;1;36mcondescending_salas\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m5bf26cc739\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS   -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (4)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m6b/e26700\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m3\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 4\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER   -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (4)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m6b/e26700\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m3\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 4\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER   -\u001b[K\n",
      "\u001b[31mERROR ~ Error executing process > 'SPLITLETTERS (1)'\u001b[K\n",
      "\u001b[K\n",
      "Caused by:\u001b[K\n",
      "  Process `SPLITLETTERS (1)` terminated with an error exit status (1)\u001b[K\n",
      "\u001b[K\n",
      "\u001b[K\n",
      "Command executed:\u001b[K\n",
      "\u001b[K\n",
      "  echo \"Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\"\u001b[K\n",
      "  echo \"[null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]\" | fold -w null | split -l 1 - chunk_ --numeric-suffixes --suffix-length=3\u001b[K\n",
      "  for file in chunk_*; do\u001b[K\n",
      "      echo \"Created file: $file with content:\"\u001b[K\n",
      "      cat $file | od -c  # Shows actual characters including nulls\u001b[K\n",
      "      mv $file ${file}.txt\u001b[K\n",
      "  done\u001b[K\n",
      "\u001b[K\n",
      "Command exit status:\u001b[K\n",
      "  1\u001b[K\n",
      "\u001b[K\n",
      "Command output:\u001b[K\n",
      "  Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\u001b[K\n",
      "  Created file: chunk_* with content:\u001b[K\n",
      "  0000000\u001b[K\n",
      "\u001b[K\n",
      "Command error:\u001b[K\n",
      "  Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\u001b[K\n",
      "  fold: invalid number of columns: ‘null’\u001b[K\n",
      "  Created file: chunk_* with content:\u001b[K\n",
      "  cat: 'chunk_*': No such file or directory\u001b[K\n",
      "  0000000\u001b[K\n",
      "  mv: cannot stat 'chunk_*': No such file or directory\u001b[K\n",
      "\u001b[K\n",
      "Work dir:\u001b[K\n",
      "  /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/ee/82ce0cf328985134bd3cc1294bd0bd\u001b[K\n",
      "\u001b[K\n",
      "Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`\u001b[K\n",
      "\u001b[K\n",
      " -- Check '.nextflow.log' file for details\u001b[39m\u001b[K\n",
      "WARN: Got an interrupted exception while taking agent result | java.lang.InterruptedException\n",
      "\u001b[42A\n",
      "\u001b[2mexecutor >  local (4)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m54/6230ac\u001b[0;2m] \u001b[0;2m\u001b[mSPLITLETTERS\u001b[33;2m (\u001b[0;33m4\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 4\u001b[31m ✘\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mCONVERTTOUPPER   -\u001b[K\n",
      "\u001b[31mERROR ~ Error executing process > 'SPLITLETTERS (1)'\u001b[K\n",
      "\u001b[K\n",
      "Caused by:\u001b[K\n",
      "  Process `SPLITLETTERS (1)` terminated with an error exit status (1)\u001b[K\n",
      "\u001b[K\n",
      "\u001b[K\n",
      "Command executed:\u001b[K\n",
      "\u001b[K\n",
      "  echo \"Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\"\u001b[K\n",
      "  echo \"[null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz]\" | fold -w null | split -l 1 - chunk_ --numeric-suffixes --suffix-length=3\u001b[K\n",
      "  for file in chunk_*; do\u001b[K\n",
      "      echo \"Created file: $file with content:\"\u001b[K\n",
      "      cat $file | od -c  # Shows actual characters including nulls\u001b[K\n",
      "      mv $file ${file}.txt\u001b[K\n",
      "  done\u001b[K\n",
      "\u001b[K\n",
      "Command exit status:\u001b[K\n",
      "  1\u001b[K\n",
      "\u001b[K\n",
      "Command output:\u001b[K\n",
      "  Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\u001b[K\n",
      "  Created file: chunk_* with content:\u001b[K\n",
      "  0000000\u001b[K\n",
      "\u001b[K\n",
      "Command error:\u001b[K\n",
      "  Processing: [null, fq_1_R1.fastq.gz, fq_1_R2.fastq.gz] with block_size: null\u001b[K\n",
      "  fold: invalid number of columns: ‘null’\u001b[K\n",
      "  Created file: chunk_* with content:\u001b[K\n",
      "  cat: 'chunk_*': No such file or directory\u001b[K\n",
      "  0000000\u001b[K\n",
      "  mv: cannot stat 'chunk_*': No such file or directory\u001b[K\n",
      "\u001b[K\n",
      "Work dir:\u001b[K\n",
      "  /home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_04/work/ee/82ce0cf328985134bd3cc1294bd0bd\u001b[K\n",
      "\u001b[K\n",
      "Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`\u001b[K\n",
      "\u001b[K\n",
      " -- Check '.nextflow.log' file for details\u001b[39m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nextflow run link_p_c.nf --step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of the provided time, I was not able to fix this error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
